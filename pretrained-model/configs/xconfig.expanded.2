# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file /home3/jicheng/w2021/lid-xvector/exp-bn/exp-lre17_train_1.5_1.5_30_overlap_27.5s_train/kaldi_xvector/configs/network.xconfig --config-dir /home3/jicheng/w2021/lid-xvector/exp-bn/exp-lre17_train_1.5_1.5_30_overlap_27.5s_train/kaldi_xvector/configs
# It contains the same content as ./xconfig but it was parsed,
# default config values were set, 
# and Descriptors (input=xxx) were normalized.
# See also ./xconfig.expanded.1

input name=input dim=80
spec-augment-layer name=spec-augment freq-max-proportion=0.3 include-in-init=True input=input time-mask-max-frames=20 time-zeroed-proportion=0.1
relu-batchnorm-layer name=tdnn1 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(Offset(spec-augment, -2), Offset(spec-augment, -1), spec-augment, Offset(spec-augment, 1), Offset(spec-augment, 2)) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn2 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=tdnn1 l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn3 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(Offset(tdnn2, -2), tdnn2, Offset(tdnn2, 2)) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn4 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=tdnn3 l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn5 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(Offset(tdnn4, -3), tdnn4, Offset(tdnn4, 3)) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn6 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=tdnn5 l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn7 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=Append(Offset(tdnn6, -4), tdnn6, Offset(tdnn6, 4)) l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn8 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=tdnn7 l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn9 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=tdnn8 l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=tdnn10 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=1500 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=tdnn9 l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
stats-layer name=stats config=mean+stddev(0:1:1:10000) dim=3000 input=tdnn10
relu-batchnorm-layer name=embedding1 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=stats l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
relu-batchnorm-layer name=embedding2 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=512 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=embedding1 l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
output-layer name=output bias-stddev=0.0 bottleneck-dim=-1 dim=14 include-log-softmax=True input=embedding2 l2-regularize= learning-rate-factor= max-change=1.5 ng-affine-options= ng-linear-options= objective-type=linear orthonormal-constraint=1.0 output-delay=0 param-stddev=0.0
