# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file /home3/jicheng/w2021/lid-xvector/exp-bn/exp-lre17_train_1.5_1.5_30_overlap_27.5s_train/kaldi_xvector/configs/network.xconfig --config-dir /home3/jicheng/w2021/lid-xvector/exp-bn/exp-lre17_train_1.5_1.5_30_overlap_27.5s_train/kaldi_xvector/configs
# It is a copy of the source from which the config files in # this directory were generated.

# please note that it is important to have input layer with the name=input
# The frame-level layers
input dim=80 name=input
spec-augment-layer name=spec-augment freq-max-proportion=0.3 time-zeroed-proportion=0.1 time-mask-max-frames=20 include-in-init=true
relu-batchnorm-layer name=tdnn1 input=Append(-2,-1,0,1,2) dim=512
relu-batchnorm-layer name=tdnn2 dim=512
relu-batchnorm-layer name=tdnn3 input=Append(-2,0,2) dim=512
relu-batchnorm-layer name=tdnn4 dim=512
relu-batchnorm-layer name=tdnn5 input=Append(-3,0,3) dim=512
relu-batchnorm-layer name=tdnn6 dim=512
relu-batchnorm-layer name=tdnn7 input=Append(-4,0,4) dim=512
relu-batchnorm-layer name=tdnn8 dim=512
relu-batchnorm-layer name=tdnn9 dim=512
relu-batchnorm-layer name=tdnn10 dim=1500

stats-layer name=stats config=mean+stddev(0:1:1:10000)

# This is where we usually extract the embedding (aka xvector) from.
relu-batchnorm-layer name=embedding1 dim=512 input=stats

# This is where another layer the embedding could be extracted
# from, but usually the previous one works better.
relu-batchnorm-layer name=embedding2 dim=512
output-layer name=output include-log-softmax=true dim=14
